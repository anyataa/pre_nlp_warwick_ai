{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "    doc = nlp(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sentences = [sent for sent in doc.sents]\n",
    "len(doc_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.  \n"
     ]
    }
   ],
   "source": [
    "print(doc_sentences[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        det        the             \n",
      "man        NOUN       poss       man             \n",
      "'s         PART       case       's              \n",
      "hands      NOUN       nsubj      hand            \n",
      "were       AUX        ROOT       be              \n",
      "behind     ADP        prep       behind          \n",
      "\n",
      "          SPACE      dep        \n",
      "               \n",
      "his        PRON       poss       his             \n",
      "back       NOUN       pobj       back            \n",
      ",          PUNCT      punct      ,               \n",
      "the        DET        det        the             \n",
      "wrists     NOUN       attr       wrist           \n",
      "bound      VERB       acl        bind            \n",
      "with       ADP        prep       with            \n",
      "a          DET        det        a               \n",
      "cord       NOUN       pobj       cord            \n",
      ".          PUNCT      punct      .               \n",
      "           SPACE      dep                        \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in doc_sentences[1]:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.dep_:{10}} {token.lemma_:{15}} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        det        the             \n",
      "man        NOUN       poss       man             \n",
      "'s         PART       case       's              \n",
      "hands      NOUN       nsubj      hand            \n",
      "were       AUX        ROOT       be              \n",
      "behind     ADP        prep       behind          \n",
      "\n",
      "          SPACE      dep        \n",
      "               \n",
      "his        PRON       poss       his             \n",
      "back       NOUN       pobj       back            \n",
      ",          PUNCT      punct      ,               \n",
      "the        DET        det        the             \n",
      "wrists     NOUN       attr       wrist           \n",
      "bound      VERB       acl        bind            \n",
      "with       ADP        prep       with            \n",
      "a          DET        det        a               \n",
      "cord       NOUN       pobj       cord            \n",
      ".          PUNCT      punct      .               \n",
      "           SPACE      dep                        \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in doc_sentences[1]:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.dep_:{10}} {token.lemma_:{15}} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13245044497498710760, 1274, 1277), (13245044497498710760, 3609, 3612)]\n"
     ]
    }
   ],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "patterns = [{\"LOWER\": \"swimming\"}, \n",
    "            {\"IS_SPACE\": True}, \n",
    "            {\"LOWER\":\"vigorously\"}]\n",
    "\n",
    "matcher.add(\"SwimmingVigorously\", [patterns])\n",
    "matches = matcher(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13245044497498710760, 1274, 1277), (13245044497498710760, 3609, 3612)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "\n",
    "print(matches)\n",
    "\n",
    "\n",
    "\n",
    "# Create visualization\n",
    "# from spacy import displacy\n",
    "# displacy.render(matches[0], style=\"ent\", manual=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swimming\n"
     ]
    }
   ],
   "source": [
    "print(doc[1274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  His brain was\n"
     ]
    }
   ],
   "source": [
    "print(doc[3600:3620])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sent in doc_sentences:\n",
    "    if matches[0][1] < sent.end:\n",
    "        print(sent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sent in doc_sentences:\n",
    "    if matches[1][1] < sent.end:\n",
    "        print(sent)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH 1: By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.   \n",
      "\n",
      "MATCH 2: The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i < len(matches):\n",
    "    for sent in doc_sentences:\n",
    "        if matches[i][1] < sent.end:\n",
    "            print(f\"MATCH {i+1}: {sent} \\n\")\n",
    "            i += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
